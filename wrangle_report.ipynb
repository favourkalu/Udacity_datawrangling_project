{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0607c5e",
   "metadata": {},
   "source": [
    "# WRANGLE REPORT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14bea96a",
   "metadata": {},
   "source": [
    "## INTRODUCTION\n",
    "\n",
    "This project dealt with wrangling data. It used a real world dataset which is a tweet archive of twitter user also known as \n",
    "WeRateDogs. WeRateDogs has over 4million followers and has international recognition. The sole purpose of this account is to rate people's dogs with a humorous comment about the dog. This project, applied the three wrangling process which is gather, access and clean to to get the dataset ready tidiness and quality wise for making insights and visualization.\n",
    "\n",
    "## DATA GATHERING\n",
    "\n",
    "This is the first stage of data wrangling. In this stage, 3 different datasets were gathered which were needed to complete the project.\n",
    "\n",
    "**twitter_archive_enhanced**: This dataset is a comma separated value (CSV) dataset which was read into pandas. It contains 2356 rows and 17 columns of the information about the tweet, dog type and engagment. This dataset was downloaded manually.\n",
    "\n",
    "**image_prediction**: This dataset was downloaded programmatically using the request library in python. It was read into pandas as tab separated value (TSV). The dataset contains 2075 rows and 12 columns with information about the dog.\n",
    "\n",
    "**tweet_json**: This dataset is an information gotten from Twitter API for each tweet's JSON data using Python's Tweepy library. tweet_id, favorite_count and retweet_count was extracted from this dataset into a pandas dataframe. It contains 2354 rows and 3 columns. \n",
    "\n",
    "\n",
    "## ACCESSING THE DATA\n",
    "\n",
    "This is the second stage of data wrangling process. In this stage, the three different datasets were accessed visually and programmatically to identify tidiness issues and quality issues.\n",
    "\n",
    "\n",
    "### twitter_archive_enhanced\n",
    "\n",
    "After a visual and programmatic accessment of the twitter_archive_enhanced dataset, it was found that there were 2 tidiness issues and 6 quality issues.\n",
    "\n",
    "**TIDINESS**\n",
    "\n",
    "** Doggo, floofer, pupper and puppo should be in one column\n",
    "\n",
    "** Timestamp should be separated into two different columns (Date and time)\n",
    "\n",
    "**QUALITY**\n",
    "\n",
    "** Invalid Dog names\n",
    "\n",
    "** Invalid or outlier in the rating_denominator column\n",
    "\n",
    "** wrong datatype for timestamp and tweet_id\n",
    "\n",
    "** Remove replies and retweets \n",
    "\n",
    "** Expanded urls are repeated in the same input\n",
    "\n",
    "** Drop in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, retweeted_status_user_id and retweeted_status_timestamp\n",
    "\n",
    "\n",
    "\n",
    "### image_prediction\n",
    "\n",
    "After a visual and programmatic accessment of the image_prediction dataset, 2 quality issues were found.\n",
    "\n",
    "**QUALITY**\n",
    "\n",
    "** Duplicate images in jpg_url column\n",
    "\n",
    "** Inconsistency in the dog breed names, some are in capital while others are in lower letters.\n",
    "\n",
    "\n",
    "### tweet_json\n",
    "\n",
    "After a visual and programmatic accessment of the image_prediction dataset, 1 tidiness issue was found.\n",
    "\n",
    "**TIDINESS**\n",
    "\n",
    "** Merge the cleaned version of the three datasets into one master dataset.\n",
    "\n",
    "\n",
    "## DATA CLEANING\n",
    "\n",
    "This is the final stage of the data wrangling process. Here, the tidiness and quality issues accessed and identified in the second satge (accessing the data) were cleaned programmatically.\n",
    "\n",
    "Below are some of the cleaning implemented on the dataset.\n",
    "\n",
    "1. The three datasets were merged into one master dataset.\n",
    "2. Irrelevant columns were dropped\n",
    "3. Datatype conversion\n",
    "4. Columns with more than one information were further broken down into more columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420c957e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
